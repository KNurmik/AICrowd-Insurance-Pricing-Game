{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/training.csv')\n",
    "\n",
    "y = df['claim_amount']\n",
    "df = df.drop(columns=['claim_amount'])\n",
    "\n",
    "def wrangle(df):\n",
    "    \n",
    "    original_len = len(df)\n",
    "    \n",
    "    # Replace 0 vehicle weight with mean\n",
    "    df.vh_weight = df.vh_weight.replace(0.0, np.mean(df[df.vh_weight > 0].vh_weight))\n",
    "    \n",
    "    # Replace NaNs with column mean\n",
    "    nans = ['vh_age', 'vh_speed', 'vh_value', 'vh_weight']\n",
    "    df[nans] = df[nans].fillna(df[nans].mean())\n",
    "    \n",
    "    # Join first year data\n",
    "    df = df.merge(df[df.year == 1.0][['id_policy', 'pol_no_claims_discount']],\n",
    "                  on='id_policy', suffixes=('', '_first'), how='left')\n",
    "    \n",
    "    # Change from beginning discount level\n",
    "    df['discount_base_change'] = df.pol_no_claims_discount - 0.631\n",
    "    # Yearly discount change over licence ownership\n",
    "    df['discount_yearly_change'] = df.discount_base_change / df.drv_age_lic1\n",
    "    \n",
    "    # Discount change from policy beginning\n",
    "    df['discount_change'] = df.pol_no_claims_discount - df.pol_no_claims_discount_first\n",
    "    # Approx. no. of claims since first year\n",
    "    df['no_claims'] = np.maximum(np.zeros_like(df.year), np.ceil(df.discount_change / 0.2))\n",
    "    \n",
    "    # Driver 1 and 2 combined info\n",
    "    df['drv_sex2'] = df.drv_sex2.replace('0', '')\n",
    "    df['drv_sexes'] = df.apply(lambda row: ''.join(sorted(row.drv_sex1 + row.drv_sex2)), axis=1)\n",
    "    df['drv_avg_age'] = np.mean(df[['drv_age1', 'drv_age2']], axis=1)\n",
    "    df['drv_avg_lic'] = np.mean(df[['drv_age_lic1', 'drv_age_lic2']], axis=1)\n",
    "    \n",
    "    # Drop unnecessary cols\n",
    "    df = df.drop(columns=['id_policy', 'drv_drv2', 'drv_sex2', 'drv_age2', 'drv_age_lic2',\n",
    "                         'vh_make_model', 'pol_pay_freq', 'pol_no_claims_discount_first'])\n",
    "    \n",
    "    # One-hot encoding for categorical variables\n",
    "    cats = ['pol_coverage', 'pol_payd', 'pol_usage', 'drv_sex1', 'vh_fuel', 'vh_type',\n",
    "           'drv_sexes']\n",
    "    df = pd.get_dummies(df, prefix=cats,\n",
    "                       columns=cats)\n",
    "    \n",
    "#     # Normalization\n",
    "#     dont_normalize = ['pol_no_claims_discount', 'discount_base_change', 'discount_yearly_change',\n",
    "#                                                                      'discount_change']\n",
    "    \n",
    "#     # Don't normalize categorical variables nor those in dont_normalize\n",
    "#     to_normalize = [elem for elem in list(df.columns) if elem not in dont_normalize \n",
    "#                     and '_'.join(elem.split('_')[:-1]) not in cats]\n",
    "\n",
    "#     if normalizer is None:\n",
    "#         normalizer = StandardScaler()\n",
    "#         normalizer = normalizer.fit(df[to_normalize])\n",
    "        \n",
    "#     df[to_normalize] = normalizer.transform(df[to_normalize])\n",
    "    \n",
    "    assert len(df) == original_len\n",
    "    return df\n",
    "\n",
    "def normalize(df, normalizer=None):\n",
    "    \n",
    "    cats = ['pol_coverage', 'pol_pay_freq', 'pol_payd', 'pol_usage', 'drv_sex1', 'vh_fuel', 'vh_type',\n",
    "           'drv_sexes']\n",
    "    dont_normalize = ['pol_no_claims_discount', 'discount_base_change', 'discount_yearly_change',\n",
    "                                                                     'discount_change']\n",
    "    \n",
    "    # Don't normalize categorical variables nor those in dont_normalize\n",
    "    to_normalize = [elem for elem in list(df.columns) if elem not in dont_normalize \n",
    "                    and '_'.join(elem.split('_')[:-1]) not in cats]\n",
    "\n",
    "    if normalizer is None:\n",
    "        normalizer = StandardScaler()\n",
    "        normalizer = normalizer.fit(df[to_normalize])\n",
    "        \n",
    "    df[to_normalize] = normalizer.transform(df[to_normalize])\n",
    "    return df, normalizer\n",
    "\n",
    "df = wrangle(df)\n",
    "\n",
    "y = y[df.year != 1]\n",
    "df = df[df.year != 1]\n",
    "\n",
    "df = df.drop(columns=['year'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=2021)\n",
    "# x_train = df[df.year!=4]\n",
    "# y_train = y[df.year!=4]\n",
    "# x_test = df[df.year==4]\n",
    "# y_test = y[df.year==4]\n",
    "\n",
    "# x_train, norm = normalize(x_train)\n",
    "# x_test, blah = normalize(x_test, norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 696.3628338194085\n",
      "Test: 664.7418476669355\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "\n",
    "train_preds = reg.predict(x_train)\n",
    "train_preds[train_preds < 0] = 0\n",
    "\n",
    "lr_test_preds = reg.predict(x_test)\n",
    "lr_test_preds[lr_test_preds < 0] = 0\n",
    "\n",
    "train_error = mean_squared_error(y_train, train_preds, squared=False)\n",
    "test_error = mean_squared_error(y_test, lr_test_preds, squared=False)\n",
    "\n",
    "print(\"Train: {}\\nTest: {}\".format(train_error, test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 696.368654728987\n",
      "Test: 664.7460102457505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "alphas = [0.001, 0.01, 0.05, 0.1, 0.15, 0.2, 0.4, 0.5, 0.8, 1, 1.5]\n",
    "ridge = RidgeCV(alphas=alphas)\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "train_preds = ridge.predict(x_train)\n",
    "train_preds[train_preds < 0] = 0\n",
    "\n",
    "test_preds = ridge.predict(x_test)\n",
    "test_preds[test_preds < 0] = 0\n",
    "\n",
    "train_error = mean_squared_error(y_train, train_preds, squared=False)\n",
    "test_error = mean_squared_error(y_test, test_preds, squared=False)\n",
    "\n",
    "print(\"Train: {}\\nTest: {}\".format(train_error, test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 692.0164200246895\n",
      "Test: 664.5876614766811\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "n_estimators = 100\n",
    "max_depth = 8\n",
    "max_features = 'log2'\n",
    "min_samples_split = 200\n",
    "max_leaf_nodes = None\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, max_leaf_nodes=max_leaf_nodes,\n",
    "                             max_features=max_features, min_samples_split=min_samples_split,\n",
    "                            random_state=2021).fit(x_train, y_train)\n",
    "\n",
    "train_preds = reg.predict(x_train)\n",
    "train_preds[train_preds < 0] = 0\n",
    "\n",
    "rf_test_preds = reg.predict(x_test)\n",
    "rf_test_preds[rf_test_preds < 0] = 0\n",
    "\n",
    "train_error = mean_squared_error(y_train, train_preds, squared=False)\n",
    "test_error = mean_squared_error(y_test, rf_test_preds, squared=False)\n",
    "\n",
    "print(\"Train: {}\\nTest: {}\".format(train_error, test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pol_no_claims_discount = 0.02185229886195946\n",
      "pol_duration = 0.01934444875792556\n",
      "pol_sit_duration = 0.03889296164747536\n",
      "drv_age1 = 0.028830085165734477\n",
      "drv_age_lic1 = 0.024833315610418412\n",
      "vh_age = 0.13854436003960954\n",
      "vh_speed = 0.03366538693796143\n",
      "vh_value = 0.08559991610900552\n",
      "vh_weight = 0.07577918785446702\n",
      "population = 0.044777588654106276\n",
      "town_surface_area = 0.04971922750832976\n",
      "discount_base_change = 0.022147245343338794\n",
      "discount_yearly_change = 0.024662015377118058\n",
      "discount_change = 0.04192945396717478\n",
      "no_claims = 0.008809912432687073\n",
      "drv_avg_age = 0.043669803029470745\n",
      "drv_avg_lic = 0.030686526476394464\n",
      "pol_coverage_Max = 0.1182591170369297\n",
      "pol_coverage_Med1 = 0.016472684307511847\n",
      "pol_coverage_Med2 = 0.031038846304237453\n",
      "pol_coverage_Min = 0.021211849291579012\n",
      "pol_payd_No = 0.001726124335330552\n",
      "pol_payd_Yes = 0.001787944437608641\n",
      "pol_usage_AllTrips = 0.004909735822445731\n",
      "pol_usage_Professional = 0.012411278402981814\n",
      "pol_usage_Retired = 0.004674117428713538\n",
      "pol_usage_WorkPrivate = 0.0055185790361278264\n",
      "drv_sex1_F = 0.0009482977353622703\n",
      "drv_sex1_M = 0.003092922275700975\n",
      "vh_fuel_Diesel = 0.013584275885030523\n",
      "vh_fuel_Gasoline = 0.012401063065003043\n",
      "vh_fuel_Hybrid = 0.0005063438421039551\n",
      "vh_type_Commercial = 0.0023612696391088275\n",
      "vh_type_Tourism = 0.002610568860648106\n",
      "drv_sexes_F = 0.007924058780016686\n",
      "drv_sexes_FF = 0.0005554959442723596\n",
      "drv_sexes_FM = 0.0011786787802301622\n",
      "drv_sexes_M = 0.0013102153729996188\n",
      "drv_sexes_MM = 0.0017727996428804223\n"
     ]
    }
   ],
   "source": [
    "for name, importance in zip(x_train.columns, reg.feature_importances_):\n",
    "     print(name, \"=\", importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 693.3443824513934\n",
      "Test: 664.6502019517762\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "reg = xgb.XGBRegressor(\n",
    "    n_estimators=15,\n",
    "    reg_lambda=0.001,\n",
    "    gamma=1,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "train_preds = reg.predict(x_train)\n",
    "train_preds[train_preds < 0] = 0\n",
    "\n",
    "test_preds = reg.predict(x_test)\n",
    "test_preds[test_preds < 0] = 0\n",
    "\n",
    "train_error = mean_squared_error(y_train, train_preds, squared=False)\n",
    "test_error = mean_squared_error(y_test, test_preds, squared=False)\n",
    "\n",
    "print(\"Train: {}\\nTest: {}\".format(train_error, test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pol_no_claims_discount = 0.090079434\n",
      "pol_duration = 0.0\n",
      "pol_sit_duration = 0.0\n",
      "drv_age1 = 0.0\n",
      "drv_age_lic1 = 0.0\n",
      "vh_age = 0.24531934\n",
      "vh_speed = 0.0\n",
      "vh_value = 0.10367675\n",
      "vh_weight = 0.0\n",
      "population = 0.0\n",
      "town_surface_area = 0.0\n",
      "discount_base_change = 0.0\n",
      "discount_yearly_change = 0.0\n",
      "discount_change = 0.06049785\n",
      "no_claims = 0.0\n",
      "drv_avg_age = 0.0\n",
      "drv_avg_lic = 0.0\n",
      "pol_coverage_Max = 0.50042665\n",
      "pol_coverage_Med1 = 0.0\n",
      "pol_coverage_Med2 = 0.0\n",
      "pol_coverage_Min = 0.0\n",
      "pol_payd_No = 0.0\n",
      "pol_payd_Yes = 0.0\n",
      "pol_usage_AllTrips = 0.0\n",
      "pol_usage_Professional = 0.0\n",
      "pol_usage_Retired = 0.0\n",
      "pol_usage_WorkPrivate = 0.0\n",
      "drv_sex1_F = 0.0\n",
      "drv_sex1_M = 0.0\n",
      "vh_fuel_Diesel = 0.0\n",
      "vh_fuel_Gasoline = 0.0\n",
      "vh_fuel_Hybrid = 0.0\n",
      "vh_type_Commercial = 0.0\n",
      "vh_type_Tourism = 0.0\n",
      "drv_sexes_F = 0.0\n",
      "drv_sexes_FF = 0.0\n",
      "drv_sexes_FM = 0.0\n",
      "drv_sexes_M = 0.0\n",
      "drv_sexes_MM = 0.0\n"
     ]
    }
   ],
   "source": [
    "for name, importance in zip(df.columns, reg.feature_importances_):\n",
    "     print(name, \"=\", importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664.4390947437056"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (rf_test_preds + test_preds + lr_test_preds) / 3.0\n",
    "mean_squared_error(y_test, a, squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
